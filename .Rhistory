qqnorm(df_madrid.train$Square.Meters - df_madrid.train$sqm_est)
qqline(df_madrid.train$Square.Meters - df_madrid.train$sqm_est, col = 'orange', lwd = 2)
# Definir data frame con los valores y que está en uno de los barrios categorizados como 2
data = data.frame(Accommodates = 6,
Bathrooms = 1,
Bedrooms = 3,
Price = 80,
Beds = 3,
Review.Scores.Rating = 80,
neighb_id = '2')
estimacion_sqm <- predict(modelMadrid, data)
# Imprimir los metros cuadrados predichos
paste('El aparatamento tiene: ', round(estimacion_sqm,2), ' m2')
paste('Los m2 aumentan por habitación extra: ', round(modelMadrid$coefficients[4], 2), ' m2')
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- which(is.na(df_filter_madrid$Square.Meters))
# Crear un dataframe temporal con las variables predictoras para las filas con valores faltantes
data_new <- data.frame(
Accommodates = df_filter_madrid$Accommodates[miss_index],
Bathrooms = df_filter_madrid$Bathrooms[miss_index],
Bedrooms = df_filter_madrid$Bedrooms[miss_index],
Price = df_filter_madrid$Price[miss_index],
Beds = df_filter_madrid$Beds[miss_index],
Review.Scores.Rating = df_filter_madrid$Review.Scores.Rating[miss_index],
neighb_id = df_filter_madrid$neighb_id[miss_index]
)
# Predice los valores faltantes utilizando el modelo
predict_values <- predict(modelMadrid, data_new)
# Asigna los valores predichos a las filas con valores faltantes en Square.Meters
df_filter_madrid$Square.Meters[miss_index] <- predict_values
df_filter_madrid
# Seleccion las columnas númericas del data frame y elimino los na
df_madrid_pca <- df_filter_madrid |> select(-c('Neighbourhood','Square.Feet','neighb_id')) |> na.omit()
# Convierto el data frame en matriz
pca_matrix <- as.matrix(df_madrid_pca)
# Creo un data frame con el apartamento que quiero buscar los más similares
new_apartment <- data.frame(Accommodates = 4, Bathrooms = 1.0, Bedrooms = 2, Beds = 4,Price = 75, Guests.Included = 2, Extra.People = 2, Review.Scores.Rating = 87, Latitude = 40.000000, Longitude = -3.00000, Square.Meters = 80.08)
# Seleccion las columnas númericas del data frame y elimino los na
df_madrid_pca <- df_filter_madrid |> select(-c('Neighbourhood','Square.Feet','neighb_id'))
# Convierto el data frame en matriz
pca_matrix <- as.matrix(df_madrid_pca)
# Creo un data frame con el apartamento que quiero buscar los más similares
new_apartment <- data.frame(Accommodates = 4, Bathrooms = 1.0, Bedrooms = 2, Beds = 4,Price = 75, Guests.Included = 2, Extra.People = 2, Review.Scores.Rating = 87, Latitude = 40.000000, Longitude = -3.00000, Square.Meters = 80.08)
# Aplico un  modelo PCA
pr_madrid <- prcomp(pca_matrix,center = TRUE, scale. = TRUE)
str(pr_madrid)
pr_madrid$sdev
pr_madrid$rotation
# Aplico el predict con el modelo anterior a mi nuevo apartamento
apartment_transform <- predict(pr_madrid, as.matrix(new_apartment))
apartment_transform
# Compruebo en el gráfico los autovalores para ver con cuantos PCA me quedo
plot(cumsum(pr_madrid$sdev^2/sum(pr_madrid$sdev^2)),main = "Autovalores")
grid()
# Asigno el numero componentes PCA
number_of_pca_components <- 6
# Asigno el número de vecinos que quiero encontrar
knn <- 5
# Me quedo con el número de coeficientes de PCA que he elegido en el apartamento de test
apart_pca <- apartment_transform[, 1:number_of_pca_components]
# Me quedo con el número de coeficientes del modelo
Amad <- pr_madrid$x[,1:number_of_pca_components]
# Calculo la distancia euclídea
dist <- rowSums((apart_pca - Amad)^2)
# Selecciono los 5 apartamentos que cumplen con la distancia
knn_tags <- order(dist,decreasing = F)[1:knn]
knn_tags
# Selecciono las filas del data frame que tienen esos apartamentos.
neigbourhood_near <- df_filter_madrid[knn_tags,]
neigbourhood_near
# Seleccion las columnas númericas del data frame y elimino los na
df_madrid_pca <- df_filter_madrid |> select(-c('Neighbourhood','Square.Feet','neighb_id'))
# Convierto el data frame en matriz
pca_matrix <- as.matrix(df_madrid_pca)
# Creo un data frame con el apartamento que quiero buscar los más similares
new_apartment <- data.frame(Accommodates = 2, Bathrooms = 1.0, Bedrooms = 2, Beds = 4,Price = 68, Guests.Included = 2, Extra.People = 2, Review.Scores.Rating = 87, Latitude = 40.000000, Longitude = -3.00000, Square.Meters = 75.08)
# Aplico un  modelo PCA
pr_madrid <- prcomp(pca_matrix,center = TRUE, scale. = TRUE)
str(pr_madrid)
pr_madrid$sdev
pr_madrid$rotation
# Aplico el predict con el modelo anterior a mi nuevo apartamento
apartment_transform <- predict(pr_madrid, as.matrix(new_apartment))
apartment_transform
# Compruebo en el gráfico los autovalores para ver con cuantos PCA me quedo
plot(cumsum(pr_madrid$sdev^2/sum(pr_madrid$sdev^2)),main = "Autovalores")
grid()
# Asigno el numero componentes PCA
number_of_pca_components <- 6
# Asigno el número de vecinos que quiero encontrar
knn <- 5
# Me quedo con el número de coeficientes de PCA que he elegido en el apartamento de test
apart_pca <- apartment_transform[, 1:number_of_pca_components]
# Me quedo con el número de coeficientes del modelo
Amad <- pr_madrid$x[,1:number_of_pca_components]
# Calculo la distancia euclídea
dist <- rowSums((apart_pca - Amad)^2)
# Selecciono los 5 apartamentos que cumplen con la distancia
knn_tags <- order(dist,decreasing = F)[1:knn]
knn_tags
# Selecciono las filas del data frame que tienen esos apartamentos.
neigbourhood_near <- df_filter_madrid[knn_tags,]
neigbourhood_near
# Selecciono las filas del data frame que tienen esos apartamentos.
neigbourhood_near <- df_madrid_pca[knn_tags,]
neigbourhood_near
# Asigno el numero componentes PCA
number_of_pca_components <- 6
# Asigno el número de vecinos que quiero encontrar
knn <- 5
# Me quedo con el número de coeficientes de PCA que he elegido en el apartamento de test
apart_pca <- apartment_transform[, 1:number_of_pca_components]
# Me quedo con el número de coeficientes del modelo
Amad <- pr_madrid$x[,1:number_of_pca_components]
# Calculo la distancia euclídea
dist <- rowSums((apart_pca - Amad)^2)
# Selecciono los 5 apartamentos que cumplen con la distancia
knn_tags <- order(dist,decreasing = F)[1:knn]
knn_tags
# Selecciono las filas del data frame que tienen esos apartamentos.
neigbourhood_near <- df_madrid_pca[knn_tags,]
neigbourhood_near
gc()
set.seed(12345)
# Selecciono los idx de forma aleatoaria, pongo una semilla para evitar cada vez tener unos resultados.
idx <- sample(1:nrow(df_filter_madrid),nrow(df_filter_madrid)*0.7)
# Carga del dataset de airbnb
airbnb <- read.csv('airbnb-listings.csv',sep = ';')
options(repr.plot.height = 4,repr.plot.width = 6,repr.plot.res = 300)
library(dplyr)
# Selección de columnas
airbnb <- airbnb[,c('City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')]
airbnb
# Creación del df de Madrid con Room Type = Entire home/apt
df_madrid <- airbnb |> filter(City == 'Madrid') |> filter(Room.Type == 'Entire home/apt')
# Convertimos los datos vacios de Neighbourhood en NA
df_madrid$Neighbourhood[which(df_madrid$Neighbourhood == '')] <- NA
# Elimimanos los datos que tienen NA en Neighbourhood y eliminamos las columnas City y Room Type
df_madrid <- df_madrid |> filter(!is.na(Neighbourhood)) |> select(-c('City','Room.Type'))
df_madrid
# Añadir columna de metros cuadrados convirtiendo la columna de pies cuadrados
rateToSquareMeter <- 0.092903
df_madrid$Square.Meters <- df_madrid$Square.Feet*rateToSquareMeter
df_madrid
# Porcentaje de apartamentos que no muestran metros cuadrados
totalApartment <- nrow(df_madrid)  # Total de apartamentos
naApartment <- sum(is.na(df_madrid$Square.Meters)) # Apartamentos que tienen Na como valor
porcentageNaApartament <- (naApartment/totalApartment)*100
paste('El porcentaje de apartamentos que no muestran los metros cuadrados es', round(porcentageNaApartament,2),'%') # Redondeo a 2 decimales
# Podemos aplicar un test binomial donde en probatility of sucess podemos ver el mismo porcentaje.
binom.test(naApartment,totalApartment)
# Porcentaje de apartamentos con 0 m2 de los apartamentos que tienen datos
apartmentSquareMeter <- df_madrid |> filter(!is.na(Square.Meters))
totalApartmentNo0 <- nrow(apartmentSquareMeter)  # Total de apartamentos de los que tenemos datos
ceroApartment <- sum(apartmentSquareMeter$Square.Meters == 0) # Apartamentos que tienen 0 como valor
porcentageCeroApartament <- (ceroApartment/totalApartmentNo0)*100
paste('El porcentaje de apartamentos con 0 metros cuadrados es', round(porcentageCeroApartament,2),'%') # Redondeo a dos decimales
#Comprobamos con un test binomial igual que en le punto anterior
binom.test(ceroApartment,totalApartmentNo0)
# Reemplazar los apartamentos con 0 m2 por NA
df_madrid$Square.Meters[which(df_madrid$Square.Meters == 0)] <- NA
df_madrid
# Pintamos el histagrama
library(ggplot2)
ggplot(data = df_madrid, aes(x = Square.Meters)) +
geom_histogram(fill = 'blue', color = 'black', bins = 20) +
xlab('Metros cuadrados') + ylab('Conteo') +
ggtitle('Histograma m2 apartamentos Madrid')
# Reemplazar los pisos con menos de 20 m2 por NA
df_madrid$Square.Meters[which(df_madrid$Square.Meters < 20)] <- NA
df_madrid
# Filtrar los barrios todos los pisos tienen Square.Meter
neighbourhood_with_metres <- unique(df_madrid$Neighbourhood[!is.na(df_madrid$Square.Meters)])
# Filtrar el dataset eliminando los pisos de los barrios sin metros cuadrados
df_filter_madrid <- df_madrid |> filter(Neighbourhood %in% neighbourhood_with_metres)
df_filter_madrid
# COMPROBAR SI SIGUE UNA DISTRIBUCIÓN NORMAL
shapiro.test(df_filter_madrid$Square.Meters)
# La hipótesis nula afirma que todos los Barrios tienen la misma media de metros cuadrados.
kruskalTest_madrid <- kruskal.test(Square.Meters ~ Neighbourhood, data = df_filter_madrid)
kruskalTest_madrid
tkyMadrid <- TukeyHSD(aov(Square.Meters ~ Neighbourhood, data = df_filter_madrid))
tkyMadrid
tkyMadrid.result <- data.frame(tkyMadrid$Neighbourhood)
cn <- sort(unique(df_filter_madrid$Neighbourhood))
resm <- matrix(NA, length(cn),length(cn))
rownames(resm) <- cn
colnames(resm) <- cn
resm[lower.tri(resm) ] <- round(tkyMadrid.result$p.adj,4)
resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)]
diag(resm) <- 1
library(ggplot2)
library(reshape2)
dfResm <- melt(resm)
ggplot(dfResm, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(colour = "black") +
geom_text(aes(label = paste(round(value*100,0),"%")),size = 3) +
scale_fill_gradient(low = "white",high = "darkorange") +
ylab("Class") + xlab("Class") + theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")
library(dendextend)
distance <- as.dist(1 - abs(resm))
hcd <- hclust(distance, method = "complete")
madrid.dend <- as.dendrogram(hcd)
madrid.dend <- set(madrid.dend,"labels_cex", 0.5)
plot(color_branches(madrid.dend,h = 0.01),horiz = TRUE,cex = 0)
abline(v = 0.1,col = "red")
library(cluster)
clusters <- cutree_1h.dendrogram(madrid.dend,h = 0.1)
ss <- silhouette(clusters, distance)
plot(ss,col = 1:max(clusters),border = NA)
df_filter_madrid$neighb_id <- clusters[df_filter_madrid$Neighbourhood]
df_filter_madrid$neighb_id <- as.factor(df_filter_madrid$neighb_id) # La paso a factor
df_filter_madrid
set.seed(12345)
# Selecciono los idx de forma aleatoaria, pongo una semilla para evitar cada vez tener unos resultados.
idx <- sample(1:nrow(df_filter_madrid),nrow(df_filter_madrid)*0.7)
# Selecciono los data frames con esos indices
df_madrid.train <- df_filter_madrid[idx,] # DATA FRAME DE TRAINING
df_madrid.test <- df_filter_madrid[-idx,] # DATA FRAME DE TESTING
df_filter_madrid
df_madrid.test
df_madrid.train
# USO UNA REGRESION LINEAL  PARA MI MODELO
modelMadrid <- lm(Square.Meters~Accommodates+Bathrooms+Bedrooms+Beds+Price+Review.Scores.Rating+neighb_id,df_madrid.train)
summary(modelMadrid)
confint(modelMadrid)
# Añado a mis data frames de training y testing una columna con la predicción del modelo
df_madrid.train$sqm_est <- predict(modelMadrid, df_madrid.train)
df_madrid.test$sqm_est <- predict(modelMadrid, df_madrid.test)
# Comparativa de los errores cuadráticos medios y R2 en training y testing
caret::postResample(pred = predict(modelMadrid, df_madrid.train), obs = df_madrid.train$Square.Meters)
caret::postResample(pred = predict(modelMadrid, df_madrid.test), obs = df_madrid.test$Square.Meters)
# Gráfica para ver la distancia de Cook
plot(cooks.distance(modelMadrid))
# Pintamos un gráfico de puntos para ver según los metros cuadrados el residuo entre el valor real y el estamido en testing.
ggplot(df_madrid.train, aes(x = Square.Meters, y = Square.Meters - sqm_est)) + geom_point()
# Comprobamos en un gráfico si lso residuos siguen una distribución normal
qqnorm(df_madrid.train$Square.Meters - df_madrid.train$sqm_est)
qqline(df_madrid.train$Square.Meters - df_madrid.train$sqm_est, col = 'orange', lwd = 2)
# Definir data frame con los valores y que está en uno de los barrios categorizados como 2
data = data.frame(Accommodates = 6,
Bathrooms = 1,
Bedrooms = 3,
Price = 80,
Beds = 3,
Review.Scores.Rating = 80,
neighb_id = '2')
estimacion_sqm <- predict(modelMadrid, data)
# Imprimir los metros cuadrados predichos
paste('El aparatamento tiene: ', round(estimacion_sqm,2), ' m2')
paste('Los m2 aumentan por habitación extra: ', round(modelMadrid$coefficients[4], 2), ' m2')
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- which(is.na(df_filter_madrid$Square.Meters))
# Crear un dataframe temporal con las variables predictoras para las filas con valores faltantes
data_new <- data.frame(
Accommodates = df_filter_madrid$Accommodates[miss_index],
Bathrooms = df_filter_madrid$Bathrooms[miss_index],
Bedrooms = df_filter_madrid$Bedrooms[miss_index],
Price = df_filter_madrid$Price[miss_index],
Beds = df_filter_madrid$Beds[miss_index],
Review.Scores.Rating = df_filter_madrid$Review.Scores.Rating[miss_index],
neighb_id = df_filter_madrid$neighb_id[miss_index]
)
# Predice los valores faltantes utilizando el modelo
predict_values <- predict(modelMadrid, data_new)
# Asigna los valores predichos a las filas con valores faltantes en Square.Meters
df_filter_madrid$Square.Meters[miss_index] <- predict_values
df_filter_madrid
# Seleccion las columnas númericas del data frame y elimino los na
df_madrid_pca <- df_filter_madrid |> select(-c('Neighbourhood','Square.Feet','neighb_id'))
# Convierto el data frame en matriz
pca_matrix <- as.matrix(df_madrid_pca)
# Creo un data frame con el apartamento que quiero buscar los más similares
new_apartment <- data.frame(Accommodates = 2, Bathrooms = 1.0, Bedrooms = 2, Beds = 4,Price = 68, Guests.Included = 2, Extra.People = 2, Review.Scores.Rating = 87, Latitude = 40.000000, Longitude = -3.00000, Square.Meters = 75.08)
# Aplico un  modelo PCA
pr_madrid <- prcomp(pca_matrix,center = TRUE, scale. = TRUE)
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- which(is.na(df_filter_madrid$Square.Meters))
miss_index
# Crear un dataframe temporal con las variables predictoras para las filas con valores faltantes
data_new <- data.frame(
Accommodates = df_filter_madrid$Accommodates[miss_index],
Bathrooms = df_filter_madrid$Bathrooms[miss_index],
Bedrooms = df_filter_madrid$Bedrooms[miss_index],
Price = df_filter_madrid$Price[miss_index],
Beds = df_filter_madrid$Beds[miss_index],
Review.Scores.Rating = df_filter_madrid$Review.Scores.Rating[miss_index],
neighb_id = df_filter_madrid$neighb_id[miss_index]
)
# Predice los valores faltantes utilizando el modelo
predict_values <- predict(modelMadrid, data_new)
# Asigna los valores predichos a las filas con valores faltantes en Square.Meters
df_filter_madrid$Square.Meters[miss_index] <- predict_values
df_filter_madrid
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- which(is.na(df_filter_madrid$Square.Meters))
# Asigna los valores predichos a las filas con valores faltantes en Square.Meters
df_filter_madrid$Square.Meters[miss_index] <- predict(modelMadrid, data.frame(
Accommodates = df_filter_madrid$Accommodates[miss_index],
Bathrooms = df_filter_madrid$Bathrooms[miss_index],
Bedrooms = df_filter_madrid$Bedrooms[miss_index],
Price = df_filter_madrid$Price[miss_index],
Beds = df_filter_madrid$Beds[miss_index],
Review.Scores.Rating = df_filter_madrid$Review.Scores.Rating[miss_index],
neighb_id = df_filter_madrid$neighb_id[miss_index]
))
df_filter_madrid
gc()
gc()
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- is.na(df_filter_madrid$Square.Meters)
# Carga del dataset de airbnb
airbnb <- read.csv('airbnb-listings.csv',sep = ';')
options(repr.plot.height = 4,repr.plot.width = 6,repr.plot.res = 300)
library(dplyr)
# Selección de columnas
airbnb <- airbnb[,c('City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')]
airbnb
# Creación del df de Madrid con Room Type = Entire home/apt
df_madrid <- airbnb |> filter(City == 'Madrid') |> filter(Room.Type == 'Entire home/apt')
# Convertimos los datos vacios de Neighbourhood en NA
df_madrid$Neighbourhood[which(df_madrid$Neighbourhood == '')] <- NA
# Elimimanos los datos que tienen NA en Neighbourhood y eliminamos las columnas City y Room Type
df_madrid <- df_madrid |> filter(!is.na(Neighbourhood)) |> select(-c('City','Room.Type'))
df_madrid
# Añadir columna de metros cuadrados convirtiendo la columna de pies cuadrados
rateToSquareMeter <- 0.092903
df_madrid$Square.Meters <- df_madrid$Square.Feet*rateToSquareMeter
df_madrid
# Porcentaje de apartamentos que no muestran metros cuadrados
totalApartment <- nrow(df_madrid)  # Total de apartamentos
naApartment <- sum(is.na(df_madrid$Square.Meters)) # Apartamentos que tienen Na como valor
porcentageNaApartament <- (naApartment/totalApartment)*100
paste('El porcentaje de apartamentos que no muestran los metros cuadrados es', round(porcentageNaApartament,2),'%') # Redondeo a 2 decimales
# Podemos aplicar un test binomial donde en probatility of sucess podemos ver el mismo porcentaje.
binom.test(naApartment,totalApartment)
# Porcentaje de apartamentos con 0 m2 de los apartamentos que tienen datos
apartmentSquareMeter <- df_madrid |> filter(!is.na(Square.Meters))
totalApartmentNo0 <- nrow(apartmentSquareMeter)  # Total de apartamentos de los que tenemos datos
ceroApartment <- sum(apartmentSquareMeter$Square.Meters == 0) # Apartamentos que tienen 0 como valor
porcentageCeroApartament <- (ceroApartment/totalApartmentNo0)*100
paste('El porcentaje de apartamentos con 0 metros cuadrados es', round(porcentageCeroApartament,2),'%') # Redondeo a dos decimales
#Comprobamos con un test binomial igual que en le punto anterior
binom.test(ceroApartment,totalApartmentNo0)
# Reemplazar los apartamentos con 0 m2 por NA
df_madrid$Square.Meters[which(df_madrid$Square.Meters == 0)] <- NA
df_madrid
# Pintamos el histagrama
library(ggplot2)
ggplot(data = df_madrid, aes(x = Square.Meters)) +
geom_histogram(fill = 'blue', color = 'black', bins = 20) +
xlab('Metros cuadrados') + ylab('Conteo') +
ggtitle('Histograma m2 apartamentos Madrid')
# Reemplazar los pisos con menos de 20 m2 por NA
df_madrid$Square.Meters[which(df_madrid$Square.Meters < 20)] <- NA
df_madrid
# Filtrar los barrios todos los pisos tienen Square.Meter
neighbourhood_with_metres <- unique(df_madrid$Neighbourhood[!is.na(df_madrid$Square.Meters)])
# Filtrar el dataset eliminando los pisos de los barrios sin metros cuadrados
df_filter_madrid <- df_madrid |> filter(Neighbourhood %in% neighbourhood_with_metres)
df_filter_madrid
# COMPROBAR SI SIGUE UNA DISTRIBUCIÓN NORMAL
shapiro.test(df_filter_madrid$Square.Meters)
# La hipótesis nula afirma que todos los Barrios tienen la misma media de metros cuadrados.
kruskalTest_madrid <- kruskal.test(Square.Meters ~ Neighbourhood, data = df_filter_madrid)
kruskalTest_madrid
tkyMadrid <- TukeyHSD(aov(Square.Meters ~ Neighbourhood, data = df_filter_madrid))
tkyMadrid
tkyMadrid.result <- data.frame(tkyMadrid$Neighbourhood)
cn <- sort(unique(df_filter_madrid$Neighbourhood))
resm <- matrix(NA, length(cn),length(cn))
rownames(resm) <- cn
colnames(resm) <- cn
resm[lower.tri(resm) ] <- round(tkyMadrid.result$p.adj,4)
resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)]
diag(resm) <- 1
library(ggplot2)
library(reshape2)
dfResm <- melt(resm)
ggplot(dfResm, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(colour = "black") +
geom_text(aes(label = paste(round(value*100,0),"%")),size = 3) +
scale_fill_gradient(low = "white",high = "darkorange") +
ylab("Class") + xlab("Class") + theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")
library(dendextend)
distance <- as.dist(1 - abs(resm))
hcd <- hclust(distance, method = "complete")
madrid.dend <- as.dendrogram(hcd)
madrid.dend <- set(madrid.dend,"labels_cex", 0.5)
plot(color_branches(madrid.dend,h = 0.01),horiz = TRUE,cex = 0)
abline(v = 0.1,col = "red")
library(cluster)
clusters <- cutree_1h.dendrogram(madrid.dend,h = 0.1)
ss <- silhouette(clusters, distance)
plot(ss,col = 1:max(clusters),border = NA)
df_filter_madrid$neighb_id <- clusters[df_filter_madrid$Neighbourhood]
df_filter_madrid$neighb_id <- as.factor(df_filter_madrid$neighb_id) # La paso a factor
df_filter_madrid
set.seed(12345)
# Selecciono los idx de forma aleatoaria, pongo una semilla para evitar cada vez tener unos resultados.
idx <- sample(1:nrow(df_filter_madrid),nrow(df_filter_madrid)*0.7)
# Selecciono los data frames con esos indices
df_madrid.train <- df_filter_madrid[idx,] # DATA FRAME DE TRAINING
df_madrid.test <- df_filter_madrid[-idx,] # DATA FRAME DE TESTING
df_filter_madrid
df_madrid.test
df_madrid.train
# USO UNA REGRESION LINEAL  PARA MI MODELO
modelMadrid <- lm(Square.Meters~Accommodates+Bathrooms+Bedrooms+Beds+Price+Review.Scores.Rating+neighb_id,df_madrid.train)
summary(modelMadrid)
confint(modelMadrid)
# Añado a mis data frames de training y testing una columna con la predicción del modelo
df_madrid.train$sqm_est <- predict(modelMadrid, df_madrid.train)
df_madrid.test$sqm_est <- predict(modelMadrid, df_madrid.test)
# Comparativa de los errores cuadráticos medios y R2 en training y testing
caret::postResample(pred = predict(modelMadrid, df_madrid.train), obs = df_madrid.train$Square.Meters)
caret::postResample(pred = predict(modelMadrid, df_madrid.test), obs = df_madrid.test$Square.Meters)
# Gráfica para ver la distancia de Cook
plot(cooks.distance(modelMadrid))
# Pintamos un gráfico de puntos para ver según los metros cuadrados el residuo entre el valor real y el estamido en testing.
ggplot(df_madrid.train, aes(x = Square.Meters, y = Square.Meters - sqm_est)) + geom_point()
# Comprobamos en un gráfico si lso residuos siguen una distribución normal
qqnorm(df_madrid.train$Square.Meters - df_madrid.train$sqm_est)
qqline(df_madrid.train$Square.Meters - df_madrid.train$sqm_est, col = 'orange', lwd = 2)
# Definir data frame con los valores y que está en uno de los barrios categorizados como 2
data = data.frame(Accommodates = 6,
Bathrooms = 1,
Bedrooms = 3,
Price = 80,
Beds = 3,
Review.Scores.Rating = 80,
neighb_id = '2')
estimacion_sqm <- predict(modelMadrid, data)
# Imprimir los metros cuadrados predichos
paste('El aparatamento tiene: ', round(estimacion_sqm,2), ' m2')
paste('Los m2 aumentan por habitación extra: ', round(modelMadrid$coefficients[4], 2), ' m2')
# Encontrar las filas con valores faltantes en Square.Meters
miss_index <- is.na(df_filter_madrid$Square.Meters)
predicted_value <- predict(modelMadrid, newdata = df_filter_madrid[miss_index, ])
# Asigna los valores predichos a las filas con valores faltantes en Square.Meters
df_filter_madrid$Square.Meters[miss_index] <- predicted_value
df_filter_madrid
# Seleccion las columnas númericas del data frame y elimino los na
df_madrid_pca <- df_filter_madrid |> select(-c('Neighbourhood','Square.Feet','neighb_id'))
# Convierto el data frame en matriz
pca_matrix <- as.matrix(df_madrid_pca)
# Creo un data frame con el apartamento que quiero buscar los más similares
new_apartment <- data.frame(Accommodates = 2, Bathrooms = 1.0, Bedrooms = 2, Beds = 4,Price = 68, Guests.Included = 2, Extra.People = 2, Review.Scores.Rating = 87, Latitude = 40.000000, Longitude = -3.00000, Square.Meters = 75.08)
# Aplico un  modelo PCA
pr_madrid <- prcomp(pca_matrix,center = TRUE, scale. = TRUE)
gc()
?read.csv
data_Kata<- read.csv(karate_competition.csv, header = T, sep = ';')
data_Kata
data_Kata <- read.csv(karate_competition.csv, header = T, sep = ';')
data_Kata <- read.csv(karate_competition.csv, header = T, sep = ';')
data_Kata <- read.csv('karate_competition.csv', header = T, sep = ';')
data_Kata
data_Kata <- read.csv('karate_competition.csv', header = T, sep = ';')
options(repr.plot.height = 4,repr.plot.width = 6,repr.plot.res = 300)
data_Kata
data_Kata <- read.csv('karate_competition.csv', sep = ';')
options(repr.plot.height = 4,repr.plot.width = 6,repr.plot.res = 300)
data_Kata
data_Kata <- read.csv('karate_competition.csv', sep = ',')
options(repr.plot.height = 4,repr.plot.width = 6,repr.plot.res = 300)
data_Kata
summary(data_Kata)
library(dplyr)
data_kata$level <- as.factor(data_Kata$level)
library(dplyr)
data_Kata$level <- as.factor(data_Kata$level)
data_Kata$kata <- as.factor(data_Kata$kata)
data_Kata$win <- as.factor(data_Kata$win)
data_Kata$Gender<- as.factor(data_Kata$Gender)
summary(data_Kata)
# Convertir a Factor algunas columnas
library(dplyr)
data_Kata$level <- as.factor(data_Kata$level)
data_Kata$kata <- as.factor(data_Kata$kata)
data_Kata$win <- as.factor(data_Kata$win)
data_Kata$Gender <- as.factor(data_Kata$Gender)
count(is.na(data_Kata))
summary(data_Kata)
# Convertir a Factor algunas columnas
library(dplyr)
data_Kata$level <- as.factor(data_Kata$level)
data_Kata$kata <- as.factor(data_Kata$kata)
data_Kata$win <- as.factor(data_Kata$win)
data_Kata$Gender <- as.factor(data_Kata$Gender)
summary(data_Kata)
data_Kata_clean <- data_Kata |> select(-c('name', 'surname'))
data_Kata_clean
data_kata_year <- data_Kata_clean |> mean(Total) |> groupby(year)
data_kata_year <- data_Kata_clean |> mean(Total) |> group_by(year)
data_Kata_clean <- as.numeric(data_Kata_clean$year)
mean_by_year <- data_Kata_clean |> mean(Total) |> group_by(year)
# Convertir a Factor algunas columnas
library(dplyr)
data_Kata$level <- as.factor(data_Kata$level)
data_Kata$kata <- as.factor(data_Kata$kata)
data_Kata$win <- as.factor(data_Kata$win)
data_Kata$Gender <- as.factor(data_Kata$Gender)
summary(data_Kata)
typeof(data_Kata$year)
#Eliminamos la columnas de name y surname de los competidores
data_Kata_clean <- data_Kata |> select(-c('name', 'surname'))
data_Kata_clean
mean_by_year <- aggregate(Total ~ year, data = data_Kata_clean, FUN = mean)
mean_by_year
